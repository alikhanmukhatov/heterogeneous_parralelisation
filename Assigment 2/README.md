# Assignment 2

## Задача 1. Введение в гетерогенную параллелизацию

### Описание
Необходимо объяснить, что такое гетерогенная параллелизация и раскрыть следующие аспекты:

1. Различия между параллельными вычислениями на CPU и GPU  
2. Преимущества гетерогенной параллелизации  
3. Примеры реальных приложений

### Решение

#### 1. Различия между параллельными вычислениями на CPU и GPU
- **CPU:** Оптимизирован для последовательных и ветвящихся задач, имеет относительно небольшое количество мощных ядер.  
- **GPU:** Оптимизирован для massively parallel вычислений, содержит сотни или тысячи лёгких ядер, выполняющих одинаковые операции над большими массивами данных.  
- **Основное отличие:** CPU хорошо работает с логикой, ветвлениями и управлением памятью, GPU — с однотипными параллельными вычислениями.

#### 2. Преимущества гетерогенной параллелизации
- Возможность совмещать сильные стороны CPU и GPU в одной системе.  
- Существенное ускорение вычислительно интенсивных задач.  
- Эффективное распределение ресурсов для разных типов задач: логика на CPU, массовые вычисления на GPU.

#### 3. Примеры реальных приложений

| Приложение | Описание | Ссылка |
|------------|----------|--------|
| DEGIMA | Суперкомпьютер для астрофизики: CPU управляет распределением задач, GPU ускоряет расчёт взаимодействия тел. | [Ссылка](https://en.wikipedia.org/wiki/DEGIMA) |
| Exscalate4Cov | Виртуальный скрининг лекарств против COVID‑19: CPU распределяет симуляции, GPU ускоряет расчёты молекулярных взаимодействий. | [Ссылка](https://en.wikipedia.org/wiki/Exscalate4Cov) |
| GAMER | GPU‑ускоренные астрофизические симуляции гидродинамики и гравитации. | [Ссылка](https://arxiv.org/abs/0907.3390) |
| Scientific simulations | Научные симуляции физических систем с использованием CPU+GPU. | [Ссылка](https://arxiv.org/abs/2409.20380) |

#### 4. Гетерогенная параллелизация
Гетерогенная параллелизация — это подход к выполнению вычислительных задач, при котором одновременно используются разные типы вычислительных устройств в одной системе,  
например центральный процессор (CPU) и графический процессор (GPU).  
Основная цель — задействовать сильные стороны каждого устройства для повышения производительности и эффективности вычислений.

### Вывод
Гетерогенная параллелизация позволяет совмещать преимущества CPU и GPU, что особенно эффективно для вычислительно интенсивных задач и научных симуляций. Применение такой параллелизации заметно ускоряет выполнение реальных проектов, таких как астрофизические симуляции и виртуальный скрининг лекарств.


# Контрольные вопросы к Assignment 2  
(OpenMP, CUDA и гетерогенные вычисления)

## 1. Что понимается под гетерогенной параллелизацией?
Гетерогенная параллелизация — это подход, при котором одновременно используются разные типы вычислительных устройств (CPU и GPU) для выполнения задач, оптимально распределяя нагрузку между ними.

## 2. В чём принципиальные различия архитектур CPU и GPU?
- **CPU:** небольшое количество мощных ядер, оптимизация под последовательные и ветвящиеся задачи.  
- **GPU:** сотни или тысячи лёгких ядер, оптимизация под однотипные параллельные операции над большими массивами данных.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
- **GPU:** массовые вычисления, обработка больших массивов данных, графика, физические и молекулярные симуляции.  
- **CPU:** логика, ветвления, управление памятью, последовательные и сложные алгоритмы.

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?
- Задачи с сильными зависимостями между итерациями цикла.  
- Алгоритмы с большим количеством ветвлений или малым количеством операций на итерацию.  
- Низкий объём данных относительно накладных расходов на управление потоками.

## 5. В чём заключается основная идея алгоритма сортировки слиянием?
Алгоритм делит массив на два подмассива, рекурсивно сортирует их, а затем сливает в один отсортированный массив. Основная идея — «разделяй и властвуй».

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
- Необходимо организовать эффективное параллельное слияние подмассивов.  
- Балансировка нагрузки между блоками и потоками GPU.  
- Ограничения памяти и необходимость координации глобальной и локальной памяти.

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?
- Размер блока определяет количество потоков в одном блоке.  
- Размер сетки определяет общее число блоков.  
- Неправильный выбор может привести к недогрузке или перегрузке GPU, снижая эффективность параллелизации.

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?
- Позволяет задействовать сильные стороны каждого устройства: CPU для ветвящихся задач, GPU для массовых параллельных операций.  
- Увеличивает общую производительность и эффективность использования ресурсов системы.

