{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM0p779Si_A1",
        "outputId": "3dd03019-b291-4f49-c4ad-26aeeb2e98b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting stack_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "// Write the following CUDA source code to a file named stack_cuda.cu\n",
        "%%writefile stack_cuda.cu\n",
        "\n",
        "// Include the CUDA runtime API for memory management, kernel launches, and atomics\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Include standard C++ input/output stream library\n",
        "#include <iostream>\n",
        "\n",
        "// Define the maximum number of elements that the stack can store\n",
        "#define STACK_CAPACITY 1024\n",
        "\n",
        "// Define the number of CUDA threads per kernel launch\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================\n",
        "// Stack structure definition\n",
        "// ======================\n",
        "\n",
        "// Define a structure that represents a stack stored in GPU global memory\n",
        "struct Stack {\n",
        "    int data[STACK_CAPACITY]; // Array that holds stack elements\n",
        "    int top;                  // Index pointing to the next free position in the stack\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// Device function: push\n",
        "// ======================\n",
        "\n",
        "// Device function that pushes a value onto the stack\n",
        "__device__ bool stack_push(Stack* s, int value) {\n",
        "\n",
        "    // Atomically increment the stack pointer and return the old value\n",
        "    int idx = atomicAdd(&s->top, 1);\n",
        "\n",
        "    // Check if the stack capacity has been exceeded\n",
        "    if (idx >= STACK_CAPACITY) {\n",
        "        // Roll back the increment if the stack is full\n",
        "        atomicSub(&s->top, 1);\n",
        "        // Indicate that the push operation failed\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store the value at the computed stack index\n",
        "    s->data[idx] = value;\n",
        "\n",
        "    // Indicate that the push operation succeeded\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Device function: pop\n",
        "// ======================\n",
        "\n",
        "// Device function that pops a value from the stack\n",
        "__device__ bool stack_pop(Stack* s, int* value) {\n",
        "\n",
        "    // Atomically decrement the stack pointer and compute the target index\n",
        "    int idx = atomicSub(&s->top, 1) - 1;\n",
        "\n",
        "    // Check if the stack is empty\n",
        "    if (idx < 0) {\n",
        "        // Restore the stack pointer if underflow occurs\n",
        "        atomicAdd(&s->top, 1);\n",
        "        // Indicate that the pop operation failed\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Read the value from the stack at the computed index\n",
        "    *value = s->data[idx];\n",
        "\n",
        "    // Indicate that the pop operation succeeded\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Kernel: parallel push\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel where each thread attempts to push a value to the stack\n",
        "__global__ void push_kernel(Stack* s) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread pushes its thread ID onto the stack\n",
        "    stack_push(s, tid);\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Kernel: parallel pop\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel where each thread attempts to pop a value from the stack\n",
        "__global__ void pop_kernel(Stack* s, int* output) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Declare a variable to store the popped value\n",
        "    int value;\n",
        "\n",
        "    // Attempt to pop a value from the stack\n",
        "    if (stack_pop(s, &value)) {\n",
        "        // Store the popped value in the output array if successful\n",
        "        output[tid] = value;\n",
        "    } else {\n",
        "        // Store -1 if the pop operation failed\n",
        "        output[tid] = -1;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Main function (host code)\n",
        "// ======================\n",
        "\n",
        "// Entry point of the host program\n",
        "int main() {\n",
        "\n",
        "    // Declare a pointer to the stack in device memory\n",
        "    Stack* d_stack;\n",
        "\n",
        "    // Declare a pointer to the output array in device memory\n",
        "    int* d_output;\n",
        "\n",
        "    // Allocate memory for the stack on the GPU\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "\n",
        "    // Allocate memory for the output array on the GPU\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Declare a stack structure on the host\n",
        "    Stack h_stack;\n",
        "\n",
        "    // Initialize the stack pointer to zero (empty stack)\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Copy the initialized stack from host memory to device memory\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel that pushes values onto the stack\n",
        "    push_kernel<<<1, THREADS>>>(d_stack);\n",
        "\n",
        "    // Synchronize to ensure the push kernel has completed\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Launch the kernel that pops values from the stack\n",
        "    pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "\n",
        "    // Synchronize to ensure the pop kernel has completed\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Declare an array on the host to store popped values\n",
        "    int h_output[THREADS];\n",
        "\n",
        "    // Copy the output data from device memory to host memory\n",
        "    cudaMemcpy(h_output, d_output, THREADS * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Initialize a counter for successful pop operations\n",
        "    int success = 0;\n",
        "\n",
        "    // Iterate through the output array\n",
        "    for (int i = 0; i < THREADS; i++) {\n",
        "        // Check if the pop operation was successful\n",
        "        if (h_output[i] != -1)\n",
        "            // Increment the success counter\n",
        "            success++;\n",
        "    }\n",
        "\n",
        "    // Print the number of successful pop operations\n",
        "    std::cout << \"Successful pops: \" << success << std::endl;\n",
        "\n",
        "    // Print the maximum possible number of successful pops\n",
        "    std::cout << \"Expected (<= capacity): \" << STACK_CAPACITY << std::endl;\n",
        "\n",
        "    // Free the stack memory on the GPU\n",
        "    cudaFree(d_stack);\n",
        "\n",
        "    // Free the output array memory on the GPU\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    // Return zero to indicate successful program execution\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc stack_cuda.cu -o stack"
      ],
      "metadata": {
        "id": "_9-pCjkvlnBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29je3ucNlqji",
        "outputId": "01ece166-e3fb-4a62-fff1-1ffbf82d9a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful pops: 256\n",
            "Expected (<= capacity): 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "// Write the following CUDA source code to a file named queue_vs_stack.cu\n",
        "%%writefile queue_vs_stack.cu\n",
        "\n",
        "// Include CUDA runtime API for memory allocation, kernel launches, and atomic operations\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Include standard C++ input/output stream library\n",
        "#include <iostream>\n",
        "\n",
        "// Define a fixed maximum capacity for both stack and queue\n",
        "#define CAPACITY 1024\n",
        "\n",
        "// Define the number of CUDA threads per kernel launch\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================\n",
        "// STACK STRUCTURE\n",
        "// ======================\n",
        "\n",
        "// Define a stack data structure stored in GPU global memory\n",
        "struct Stack {\n",
        "    int data[CAPACITY];   // Array used to store stack elements\n",
        "    int top;              // Index pointing to the top of the stack\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// QUEUE STRUCTURE\n",
        "// ======================\n",
        "\n",
        "// Define a queue data structure stored in GPU global memory\n",
        "struct Queue {\n",
        "    int data[CAPACITY];   // Array used to store queue elements\n",
        "    int head;             // Index for dequeue operations\n",
        "    int tail;             // Index for enqueue operations\n",
        "    int size;             // Current number of elements in the queue\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// STACK PUSH (device)\n",
        "// ======================\n",
        "\n",
        "// Device function to push a value onto the stack\n",
        "__device__ bool stack_push(Stack* s, int value) {\n",
        "\n",
        "    // Atomically increment the stack pointer and get the old index\n",
        "    int idx = atomicAdd(&s->top, 1);\n",
        "\n",
        "    // Check if the stack exceeds its capacity\n",
        "    if (idx >= CAPACITY) {\n",
        "        // Roll back the increment if the stack is full\n",
        "        atomicSub(&s->top, 1);\n",
        "        // Indicate push failure\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store the value at the computed stack index\n",
        "    s->data[idx] = value;\n",
        "    // Indicate push success\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// STACK POP (device)\n",
        "// ======================\n",
        "\n",
        "// Device function to pop a value from the stack\n",
        "__device__ bool stack_pop(Stack* s, int* value) {\n",
        "\n",
        "    // Atomically decrement the stack pointer and compute index\n",
        "    int idx = atomicSub(&s->top, 1) - 1;\n",
        "\n",
        "    // Check if the stack is empty\n",
        "    if (idx < 0) {\n",
        "        // Restore the stack pointer if underflow occurs\n",
        "        atomicAdd(&s->top, 1);\n",
        "        // Indicate pop failure\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Load the value from the stack\n",
        "    *value = s->data[idx];\n",
        "    // Indicate pop success\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE ENQUEUE (device)\n",
        "// ======================\n",
        "\n",
        "// Device function to add a value to the queue\n",
        "__device__ bool queue_enqueue(Queue* q, int value) {\n",
        "\n",
        "    // Atomically increment the tail index to reserve a slot\n",
        "    int pos = atomicAdd(&q->tail, 1);\n",
        "\n",
        "    // Atomically increment the size and check if queue is full\n",
        "    if (atomicAdd(&q->size, 1) >= CAPACITY) {\n",
        "        // Roll back tail increment\n",
        "        atomicSub(&q->tail, 1);\n",
        "        // Roll back size increment\n",
        "        atomicSub(&q->size, 1);\n",
        "        // Indicate enqueue failure\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store the value using circular buffer indexing\n",
        "    q->data[pos % CAPACITY] = value;\n",
        "    // Indicate enqueue success\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE DEQUEUE (device)\n",
        "// ======================\n",
        "\n",
        "// Device function to remove a value from the queue\n",
        "__device__ bool queue_dequeue(Queue* q, int* value) {\n",
        "\n",
        "    // Atomically decrement the size and check if queue is empty\n",
        "    if (atomicSub(&q->size, 1) <= 0) {\n",
        "        // Restore size if queue was empty\n",
        "        atomicAdd(&q->size, 1);\n",
        "        // Indicate dequeue failure\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Atomically increment the head index to reserve dequeue position\n",
        "    int pos = atomicAdd(&q->head, 1);\n",
        "\n",
        "    // Load the value using circular buffer indexing\n",
        "    *value = q->data[pos % CAPACITY];\n",
        "    // Indicate dequeue success\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// STACK KERNELS\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel for parallel stack push\n",
        "__global__ void stack_push_kernel(Stack* s) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread pushes its thread ID onto the stack\n",
        "    stack_push(s, tid);\n",
        "}\n",
        "\n",
        "// CUDA kernel for parallel stack pop\n",
        "__global__ void stack_pop_kernel(Stack* s, int* out) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Declare variable to store popped value\n",
        "    int value;\n",
        "\n",
        "    // Attempt to pop from the stack\n",
        "    if (stack_pop(s, &value))\n",
        "        // Store popped value if successful\n",
        "        out[tid] = value;\n",
        "    else\n",
        "        // Store -1 if pop fails\n",
        "        out[tid] = -1;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE KERNELS\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel for parallel enqueue\n",
        "__global__ void queue_enqueue_kernel(Queue* q) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread enqueues its thread ID\n",
        "    queue_enqueue(q, tid);\n",
        "}\n",
        "\n",
        "// CUDA kernel for parallel dequeue\n",
        "__global__ void queue_dequeue_kernel(Queue* q, int* out) {\n",
        "\n",
        "    // Compute the global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Declare variable to store dequeued value\n",
        "    int value;\n",
        "\n",
        "    // Attempt to dequeue from the queue\n",
        "    if (queue_dequeue(q, &value))\n",
        "        // Store dequeued value if successful\n",
        "        out[tid] = value;\n",
        "    else\n",
        "        // Store -1 if dequeue fails\n",
        "        out[tid] = -1;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// MAIN FUNCTION\n",
        "// ======================\n",
        "\n",
        "// Program entry point\n",
        "int main() {\n",
        "\n",
        "    // Declare device pointers for stack, queue, and output array\n",
        "    Stack* d_stack;\n",
        "    Queue* d_queue;\n",
        "    int* d_output;\n",
        "\n",
        "    // Allocate memory on the GPU for the stack\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "    // Allocate memory on the GPU for the queue\n",
        "    cudaMalloc(&d_queue, sizeof(Queue));\n",
        "    // Allocate memory on the GPU for the output array\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Declare and initialize host-side stack\n",
        "    Stack h_stack;\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Declare and initialize host-side queue\n",
        "    Queue h_queue;\n",
        "    h_queue.head = 0;\n",
        "    h_queue.tail = 0;\n",
        "    h_queue.size = 0;\n",
        "\n",
        "    // Copy initialized stack from host to device memory\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "    // Copy initialized queue from host to device memory\n",
        "    cudaMemcpy(d_queue, &h_queue, sizeof(Queue), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Declare CUDA events for timing measurements\n",
        "    cudaEvent_t start, stop;\n",
        "    // Create start event\n",
        "    cudaEventCreate(&start);\n",
        "    // Create stop event\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // ======================\n",
        "    // STACK TIMING\n",
        "    // ======================\n",
        "\n",
        "    // Record the start time\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch stack push kernel\n",
        "    stack_push_kernel<<<1, THREADS>>>(d_stack);\n",
        "    // Launch stack pop kernel\n",
        "    stack_pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "\n",
        "    // Record the stop time\n",
        "    cudaEventRecord(stop);\n",
        "    // Synchronize to ensure kernels have finished\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Variable to store stack execution time\n",
        "    float stack_time;\n",
        "    // Compute elapsed time for stack operations\n",
        "    cudaEventElapsedTime(&stack_time, start, stop);\n",
        "\n",
        "    // ======================\n",
        "    // QUEUE TIMING\n",
        "    // ======================\n",
        "\n",
        "    // Record the start time\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch queue enqueue kernel\n",
        "    queue_enqueue_kernel<<<1, THREADS>>>(d_queue);\n",
        "    // Launch queue dequeue kernel\n",
        "    queue_dequeue_kernel<<<1, THREADS>>>(d_queue, d_output);\n",
        "\n",
        "    // Record the stop time\n",
        "    cudaEventRecord(stop);\n",
        "    // Synchronize to ensure kernels have finished\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Variable to store queue execution time\n",
        "    float queue_time;\n",
        "    // Compute elapsed time for queue operations\n",
        "    cudaEventElapsedTime(&queue_time, start, stop);\n",
        "\n",
        "    // ======================\n",
        "    // OUTPUT RESULTS\n",
        "    // ======================\n",
        "\n",
        "    // Print stack execution time\n",
        "    std::cout << \"Stack execution time: \" << stack_time << \" ms\" << std::endl;\n",
        "    // Print queue execution time\n",
        "    std::cout << \"Queue execution time: \" << queue_time << \" ms\" << std::endl;\n",
        "\n",
        "    // Free stack memory on the GPU\n",
        "    cudaFree(d_stack);\n",
        "    // Free queue memory on the GPU\n",
        "    cudaFree(d_queue);\n",
        "    // Free output array memory on the GPU\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    // Return zero to indicate successful execution\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wStxmIeImh6o",
        "outputId": "f7eb02a9-2757-4877-c3d6-5dfc80f3d3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing queue_vs_stack.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc queue_vs_stack.cu -o queue_vs_stack"
      ],
      "metadata": {
        "id": "JVPlqSTtmiuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./queue_vs_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM3MdyTVmpQc",
        "outputId": "a795582f-e3ab-45d2-b148-ba258434d775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stack execution time: 7.5271 ms\n",
            "Queue execution time: 0.002048 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answers to Control Questions\n",
        "\n",
        "## 1. What is the difference between a stack and a queue?\n",
        "\n",
        "A stack is a data structure that follows the **LIFO (Last In, First Out)** principle, where the last inserted element is removed first. A queue follows the **FIFO (First In, First Out)** principle, where the first inserted element is removed first.  \n",
        "Stacks use a single pointer (top), while queues require at least two pointers (head and tail), making queues more complex to implement in parallel environments.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What problems arise during parallel access to data?\n",
        "\n",
        "Parallel access can lead to **race conditions**, where multiple threads read and write shared data simultaneously, producing incorrect results. Other issues include **data corruption**, **lost updates**, **inconsistent states**, and **non-deterministic behavior**, making debugging and correctness verification difficult.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. How do atomic operations help avoid conflicts in parallel data structures?\n",
        "\n",
        "Atomic operations ensure that read-modify-write sequences are executed as a single, indivisible operation. This prevents multiple threads from modifying the same memory location at the same time, eliminating race conditions and ensuring correctness when updating shared variables such as stack pointers or queue indices.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. What CUDA memory types are used to store data?\n",
        "\n",
        "CUDA provides several memory types:\n",
        "- **Global memory**: Large and accessible by all threads, but has high latency.\n",
        "- **Shared memory**: Fast memory shared among threads within the same block.\n",
        "- **Local memory (registers)**: Private to each thread and very fast but limited in size.\n",
        "- **Constant memory**: Read-only memory optimized for broadcast to many threads.\n",
        "- **Texture memory**: Cached memory optimized for spatial access patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. How does thread synchronization affect performance?\n",
        "\n",
        "Synchronization ensures correct execution order but introduces overhead. Excessive synchronization can serialize parallel execution, reduce occupancy, and lower overall performance. Efficient GPU programs minimize synchronization while still guaranteeing correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Why is shared memory important for optimizing parallel data structures?\n",
        "\n",
        "Shared memory has much lower latency than global memory and allows fast data exchange between threads in the same block. Using shared memory reduces global memory access, improves memory coalescing, and significantly increases the performance of parallel data structures such as stacks, queues, and reduction algorithms.\n"
      ],
      "metadata": {
        "id": "PFr_JTtVnAiI"
      }
    }
  ]
}