{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM0p779Si_A1",
        "outputId": "3dd03019-b291-4f49-c4ad-26aeeb2e98b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting stack_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stack_cuda.cu\n",
        "\n",
        "// Include CUDA runtime API (memory management, kernel launch, atomics)\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Include standard C++ input/output stream\n",
        "#include <iostream>\n",
        "\n",
        "// Maximum number of elements the stack can hold\n",
        "#define STACK_CAPACITY 1024\n",
        "\n",
        "// Number of CUDA threads used in kernels\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================\n",
        "// Stack structure definition\n",
        "// ======================\n",
        "\n",
        "// Structure representing a stack in GPU global memory\n",
        "struct Stack {\n",
        "    int data[STACK_CAPACITY]; // Fixed-size array storing stack elements\n",
        "    int top;                  // Index of the next free position (stack pointer)\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// Device function: push\n",
        "// ======================\n",
        "\n",
        "// Pushes a value onto the stack\n",
        "// Returns true if successful, false if stack is full\n",
        "__device__ bool stack_push(Stack* s, int value) {\n",
        "\n",
        "    // Atomically increment stack pointer and get old value\n",
        "    int idx = atomicAdd(&s->top, 1);\n",
        "\n",
        "    // Check for stack overflow\n",
        "    if (idx >= STACK_CAPACITY) {\n",
        "        // Roll back the increment if overflow occurred\n",
        "        atomicSub(&s->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store value at the allocated stack position\n",
        "    s->data[idx] = value;\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Device function: pop\n",
        "// ======================\n",
        "\n",
        "// Pops a value from the stack\n",
        "// Stores popped value in *value\n",
        "// Returns true if successful, false if stack is empty\n",
        "__device__ bool stack_pop(Stack* s, int* value) {\n",
        "\n",
        "    // Atomically decrement stack pointer and get previous index\n",
        "    int idx = atomicSub(&s->top, 1) - 1;\n",
        "\n",
        "    // Check for stack underflow\n",
        "    if (idx < 0) {\n",
        "        // Roll back decrement if stack was empty\n",
        "        atomicAdd(&s->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Retrieve value from stack\n",
        "    *value = s->data[idx];\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Kernel: parallel push\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel where multiple threads push values concurrently\n",
        "__global__ void push_kernel(Stack* s) {\n",
        "\n",
        "    // Compute global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread attempts to push its thread ID\n",
        "    stack_push(s, tid);\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Kernel: parallel pop\n",
        "// ======================\n",
        "\n",
        "// CUDA kernel where multiple threads pop values concurrently\n",
        "__global__ void pop_kernel(Stack* s, int* output) {\n",
        "\n",
        "    // Compute global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    int value;\n",
        "\n",
        "    // Attempt to pop from stack\n",
        "    if (stack_pop(s, &value)) {\n",
        "        // Store popped value if successful\n",
        "        output[tid] = value;\n",
        "    } else {\n",
        "        // Mark failed pop (stack empty)\n",
        "        output[tid] = -1;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// Main function (host code)\n",
        "// ======================\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Pointer to stack allocated in GPU memory\n",
        "    Stack* d_stack;\n",
        "\n",
        "    // Pointer to output array in GPU memory\n",
        "    int* d_output;\n",
        "\n",
        "    // Allocate memory for stack on GPU\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "\n",
        "    // Allocate memory for output array on GPU\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Host-side stack structure\n",
        "    Stack h_stack;\n",
        "\n",
        "    // Initialize stack pointer to zero (empty stack)\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Copy initialized stack from host to device\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel to push values in parallel\n",
        "    push_kernel<<<1, THREADS>>>(d_stack);\n",
        "\n",
        "    // Wait until push kernel finishes\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Launch kernel to pop values in parallel\n",
        "    pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "\n",
        "    // Wait until pop kernel finishes\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Host-side array to store popped values\n",
        "    int h_output[THREADS];\n",
        "\n",
        "    // Copy popped values from device to host\n",
        "    cudaMemcpy(h_output, d_output, THREADS * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Counter for successful pop operations\n",
        "    int success = 0;\n",
        "\n",
        "    // Check correctness of pops\n",
        "    for (int i = 0; i < THREADS; i++) {\n",
        "        if (h_output[i] != -1)\n",
        "            success++;\n",
        "    }\n",
        "\n",
        "    // Print results\n",
        "    std::cout << \"Successful pops: \" << success << std::endl;\n",
        "    std::cout << \"Expected (<= capacity): \" << STACK_CAPACITY << std::endl;\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc stack_cuda.cu -o stack"
      ],
      "metadata": {
        "id": "_9-pCjkvlnBl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29je3ucNlqji",
        "outputId": "01ece166-e3fb-4a62-fff1-1ffbf82d9a27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful pops: 256\n",
            "Expected (<= capacity): 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile queue_vs_stack.cu\n",
        "\n",
        "// CUDA runtime API (memory management, kernel launches, atomics)\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Standard C++ input/output\n",
        "#include <iostream>\n",
        "\n",
        "// Fixed capacity for both stack and queue\n",
        "#define CAPACITY 1024\n",
        "\n",
        "// Number of CUDA threads\n",
        "#define THREADS 256\n",
        "\n",
        "// ======================\n",
        "// STACK STRUCTURE\n",
        "// ======================\n",
        "\n",
        "// Stack stored in global memory\n",
        "struct Stack {\n",
        "    int data[CAPACITY];   // Stack storage\n",
        "    int top;              // Stack pointer\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// QUEUE STRUCTURE\n",
        "// ======================\n",
        "\n",
        "// Queue stored in global memory (circular buffer)\n",
        "struct Queue {\n",
        "    int data[CAPACITY];   // Queue storage\n",
        "    int head;             // Index for dequeue\n",
        "    int tail;             // Index for enqueue\n",
        "    int size;             // Current number of elements\n",
        "};\n",
        "\n",
        "// ======================\n",
        "// STACK PUSH (device)\n",
        "// ======================\n",
        "\n",
        "// Push value onto stack\n",
        "__device__ bool stack_push(Stack* s, int value) {\n",
        "\n",
        "    // Atomically increment stack pointer\n",
        "    int idx = atomicAdd(&s->top, 1);\n",
        "\n",
        "    // Check overflow\n",
        "    if (idx >= CAPACITY) {\n",
        "        // Roll back if full\n",
        "        atomicSub(&s->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store value\n",
        "    s->data[idx] = value;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// STACK POP (device)\n",
        "// ======================\n",
        "\n",
        "// Pop value from stack\n",
        "__device__ bool stack_pop(Stack* s, int* value) {\n",
        "\n",
        "    // Atomically decrement stack pointer\n",
        "    int idx = atomicSub(&s->top, 1) - 1;\n",
        "\n",
        "    // Check underflow\n",
        "    if (idx < 0) {\n",
        "        // Roll back if empty\n",
        "        atomicAdd(&s->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Load value\n",
        "    *value = s->data[idx];\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE ENQUEUE (device)\n",
        "// ======================\n",
        "\n",
        "// Add value to queue\n",
        "__device__ bool queue_enqueue(Queue* q, int value) {\n",
        "\n",
        "    // Atomically reserve a position\n",
        "    int pos = atomicAdd(&q->tail, 1);\n",
        "\n",
        "    // Check if queue is full\n",
        "    if (atomicAdd(&q->size, 1) >= CAPACITY) {\n",
        "        // Roll back changes\n",
        "        atomicSub(&q->tail, 1);\n",
        "        atomicSub(&q->size, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Store value using circular indexing\n",
        "    q->data[pos % CAPACITY] = value;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE DEQUEUE (device)\n",
        "// ======================\n",
        "\n",
        "// Remove value from queue\n",
        "__device__ bool queue_dequeue(Queue* q, int* value) {\n",
        "\n",
        "    // Check if queue is empty\n",
        "    if (atomicSub(&q->size, 1) <= 0) {\n",
        "        // Roll back if empty\n",
        "        atomicAdd(&q->size, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Atomically reserve dequeue position\n",
        "    int pos = atomicAdd(&q->head, 1);\n",
        "\n",
        "    // Load value using circular indexing\n",
        "    *value = q->data[pos % CAPACITY];\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// STACK KERNELS\n",
        "// ======================\n",
        "\n",
        "// Parallel stack push\n",
        "__global__ void stack_push_kernel(Stack* s) {\n",
        "\n",
        "    // Global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread pushes its ID\n",
        "    stack_push(s, tid);\n",
        "}\n",
        "\n",
        "// Parallel stack pop\n",
        "__global__ void stack_pop_kernel(Stack* s, int* out) {\n",
        "\n",
        "    // Global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    int value;\n",
        "\n",
        "    // Attempt pop\n",
        "    if (stack_pop(s, &value))\n",
        "        out[tid] = value;\n",
        "    else\n",
        "        out[tid] = -1;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// QUEUE KERNELS\n",
        "// ======================\n",
        "\n",
        "// Parallel enqueue\n",
        "__global__ void queue_enqueue_kernel(Queue* q) {\n",
        "\n",
        "    // Global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Each thread enqueues its ID\n",
        "    queue_enqueue(q, tid);\n",
        "}\n",
        "\n",
        "// Parallel dequeue\n",
        "__global__ void queue_dequeue_kernel(Queue* q, int* out) {\n",
        "\n",
        "    // Global thread index\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    int value;\n",
        "\n",
        "    // Attempt dequeue\n",
        "    if (queue_dequeue(q, &value))\n",
        "        out[tid] = value;\n",
        "    else\n",
        "        out[tid] = -1;\n",
        "}\n",
        "\n",
        "// ======================\n",
        "// MAIN FUNCTION\n",
        "// ======================\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Device pointers\n",
        "    Stack* d_stack;\n",
        "    Queue* d_queue;\n",
        "    int* d_output;\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "    cudaMalloc(&d_queue, sizeof(Queue));\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Host stack initialization\n",
        "    Stack h_stack;\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Host queue initialization\n",
        "    Queue h_queue;\n",
        "    h_queue.head = 0;\n",
        "    h_queue.tail = 0;\n",
        "    h_queue.size = 0;\n",
        "\n",
        "    // Copy to device\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_queue, &h_queue, sizeof(Queue), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // ======================\n",
        "    // STACK TIMING\n",
        "    // ======================\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    stack_push_kernel<<<1, THREADS>>>(d_stack);\n",
        "    stack_pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float stack_time;\n",
        "    cudaEventElapsedTime(&stack_time, start, stop);\n",
        "\n",
        "    // ======================\n",
        "    // QUEUE TIMING\n",
        "    // ======================\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    queue_enqueue_kernel<<<1, THREADS>>>(d_queue);\n",
        "    queue_dequeue_kernel<<<1, THREADS>>>(d_queue, d_output);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float queue_time;\n",
        "    cudaEventElapsedTime(&queue_time, start, stop);\n",
        "\n",
        "    // ======================\n",
        "    // OUTPUT RESULTS\n",
        "    // ======================\n",
        "\n",
        "    std::cout << \"Stack execution time: \" << stack_time << \" ms\" << std::endl;\n",
        "    std::cout << \"Queue execution time: \" << queue_time << \" ms\" << std::endl;\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_queue);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wStxmIeImh6o",
        "outputId": "f7eb02a9-2757-4877-c3d6-5dfc80f3d3e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing queue_vs_stack.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc queue_vs_stack.cu -o queue_vs_stack"
      ],
      "metadata": {
        "id": "JVPlqSTtmiuc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./queue_vs_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM3MdyTVmpQc",
        "outputId": "a795582f-e3ab-45d2-b148-ba258434d775"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stack execution time: 7.5271 ms\n",
            "Queue execution time: 0.002048 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answers to Control Questions\n",
        "\n",
        "## 1. What is the difference between a stack and a queue?\n",
        "\n",
        "A stack is a data structure that follows the **LIFO (Last In, First Out)** principle, where the last inserted element is removed first. A queue follows the **FIFO (First In, First Out)** principle, where the first inserted element is removed first.  \n",
        "Stacks use a single pointer (top), while queues require at least two pointers (head and tail), making queues more complex to implement in parallel environments.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What problems arise during parallel access to data?\n",
        "\n",
        "Parallel access can lead to **race conditions**, where multiple threads read and write shared data simultaneously, producing incorrect results. Other issues include **data corruption**, **lost updates**, **inconsistent states**, and **non-deterministic behavior**, making debugging and correctness verification difficult.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. How do atomic operations help avoid conflicts in parallel data structures?\n",
        "\n",
        "Atomic operations ensure that read-modify-write sequences are executed as a single, indivisible operation. This prevents multiple threads from modifying the same memory location at the same time, eliminating race conditions and ensuring correctness when updating shared variables such as stack pointers or queue indices.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. What CUDA memory types are used to store data?\n",
        "\n",
        "CUDA provides several memory types:\n",
        "- **Global memory**: Large and accessible by all threads, but has high latency.\n",
        "- **Shared memory**: Fast memory shared among threads within the same block.\n",
        "- **Local memory (registers)**: Private to each thread and very fast but limited in size.\n",
        "- **Constant memory**: Read-only memory optimized for broadcast to many threads.\n",
        "- **Texture memory**: Cached memory optimized for spatial access patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. How does thread synchronization affect performance?\n",
        "\n",
        "Synchronization ensures correct execution order but introduces overhead. Excessive synchronization can serialize parallel execution, reduce occupancy, and lower overall performance. Efficient GPU programs minimize synchronization while still guaranteeing correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Why is shared memory important for optimizing parallel data structures?\n",
        "\n",
        "Shared memory has much lower latency than global memory and allows fast data exchange between threads in the same block. Using shared memory reduces global memory access, improves memory coalescing, and significantly increases the performance of parallel data structures such as stacks, queues, and reduction algorithms.\n"
      ],
      "metadata": {
        "id": "PFr_JTtVnAiI"
      }
    }
  ]
}