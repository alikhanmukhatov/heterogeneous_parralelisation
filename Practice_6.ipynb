{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv20ikjap9sW",
        "outputId": "c8b4093a-782a-4196-80ab-52865ccc8428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cl\n"
          ]
        }
      ],
      "source": [
        "%%writefile kernel.cl\n",
        "__kernel void vector_add(\n",
        "    __global const float* A,\n",
        "    __global const float* B,\n",
        "    __global float* C\n",
        ") {\n",
        "    int id = get_global_id(0);\n",
        "    C[id] = A[id] + B[id];\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "// Write the following C++ OpenCL program to a file named vector_add.cpp\n",
        "%%writefile vector_add.cpp\n",
        "\n",
        "// Specify the target OpenCL version (OpenCL 1.2)\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "\n",
        "// Include the main OpenCL header\n",
        "#include <CL/cl.h>\n",
        "\n",
        "// Include standard C++ input/output stream library\n",
        "#include <iostream>\n",
        "\n",
        "// Include C++ vector container\n",
        "#include <vector>\n",
        "\n",
        "// Include file stream library for reading kernel source\n",
        "#include <fstream>\n",
        "\n",
        "// Include chrono library for timing measurements\n",
        "#include <chrono>\n",
        "\n",
        "// Function to load OpenCL kernel source code from a file\n",
        "std::string loadKernel(const char* filename) {\n",
        "\n",
        "    // Open the kernel source file\n",
        "    std::ifstream file(filename);\n",
        "\n",
        "    // Read the entire file into a string and return it\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),   // Iterator to beginning of file\n",
        "        std::istreambuf_iterator<char>()         // Iterator to end of file\n",
        "    );\n",
        "}\n",
        "\n",
        "// Main program entry point\n",
        "int main() {\n",
        "\n",
        "    // Define number of elements (2^20)\n",
        "    const int N = 1 << 20;\n",
        "\n",
        "    // Compute total size in bytes for one vector\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Create input vector A and initialize all elements to 1.0\n",
        "    std::vector<float> A(N, 1.0f);\n",
        "\n",
        "    // Create input vector B and initialize all elements to 2.0\n",
        "    std::vector<float> B(N, 2.0f);\n",
        "\n",
        "    // Create output vector C (uninitialized)\n",
        "    std::vector<float> C(N);\n",
        "\n",
        "    // Declare OpenCL platform identifier\n",
        "    cl_platform_id platform;\n",
        "\n",
        "    // Declare OpenCL device identifier\n",
        "    cl_device_id device;\n",
        "\n",
        "    // Get the first available OpenCL platform\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "\n",
        "    // Get the first available device from the platform\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 1, &device, nullptr);\n",
        "\n",
        "    // Create an OpenCL context for the selected device\n",
        "    cl_context context = clCreateContext(\n",
        "        nullptr,        // Default context properties\n",
        "        1,              // Number of devices\n",
        "        &device,        // Device list\n",
        "        nullptr,        // No callback\n",
        "        nullptr,        // No user data\n",
        "        nullptr         // No error code return\n",
        "    );\n",
        "\n",
        "    // Create a command queue for the device\n",
        "    cl_command_queue queue = clCreateCommandQueue(\n",
        "        context,        // OpenCL context\n",
        "        device,         // Target device\n",
        "        0,              // Queue properties\n",
        "        nullptr         // No error code return\n",
        "    );\n",
        "\n",
        "    // Create device buffer for vector A and copy host data to device\n",
        "    cl_mem dA = clCreateBuffer(\n",
        "        context,                                // OpenCL context\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,// Read-only, copy from host\n",
        "        size,                                   // Buffer size\n",
        "        A.data(),                               // Host pointer\n",
        "        nullptr                                 // No error code return\n",
        "    );\n",
        "\n",
        "    // Create device buffer for vector B and copy host data to device\n",
        "    cl_mem dB = clCreateBuffer(\n",
        "        context,                                // OpenCL context\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,// Read-only, copy from host\n",
        "        size,                                   // Buffer size\n",
        "        B.data(),                               // Host pointer\n",
        "        nullptr                                 // No error code return\n",
        "    );\n",
        "\n",
        "    // Create device buffer for vector C (output only)\n",
        "    cl_mem dC = clCreateBuffer(\n",
        "        context,            // OpenCL context\n",
        "        CL_MEM_WRITE_ONLY,  // Write-only buffer\n",
        "        size,               // Buffer size\n",
        "        nullptr,            // No host pointer\n",
        "        nullptr             // No error code return\n",
        "    );\n",
        "\n",
        "    // Load kernel source code from file \"kernel.cl\"\n",
        "    std::string srcCode = loadKernel(\"kernel.cl\");\n",
        "\n",
        "    // Convert kernel source to C-style string\n",
        "    const char* src = srcCode.c_str();\n",
        "\n",
        "    // Create OpenCL program from kernel source\n",
        "    cl_program program = clCreateProgramWithSource(\n",
        "        context,    // OpenCL context\n",
        "        1,          // Number of source strings\n",
        "        &src,       // Pointer to source code\n",
        "        nullptr,    // Source lengths (null-terminated)\n",
        "        nullptr     // No error code return\n",
        "    );\n",
        "\n",
        "    // Build (compile) the OpenCL program for the device\n",
        "    clBuildProgram(\n",
        "        program,    // OpenCL program\n",
        "        1,          // Number of devices\n",
        "        &device,    // Device list\n",
        "        nullptr,    // Compiler options\n",
        "        nullptr,    // No callback\n",
        "        nullptr     // No user data\n",
        "    );\n",
        "\n",
        "    // Create kernel object from the compiled program\n",
        "    cl_kernel kernel = clCreateKernel(\n",
        "        program,        // Compiled program\n",
        "        \"vector_add\",   // Kernel function name\n",
        "        nullptr         // No error code return\n",
        "    );\n",
        "\n",
        "    // Set kernel argument 0 (input vector A)\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "\n",
        "    // Set kernel argument 1 (input vector B)\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "\n",
        "    // Set kernel argument 2 (output vector C)\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "\n",
        "    // Define global work size (one work-item per element)\n",
        "    size_t globalSize = N;\n",
        "\n",
        "    // Record start time before kernel execution\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Enqueue kernel for execution\n",
        "    clEnqueueNDRangeKernel(\n",
        "        queue,         // Command queue\n",
        "        kernel,        // Kernel to execute\n",
        "        1,             // Number of dimensions\n",
        "        nullptr,       // Global work offset\n",
        "        &globalSize,   // Global work size\n",
        "        nullptr,       // Local work size (let OpenCL decide)\n",
        "        0,             // Number of events to wait for\n",
        "        nullptr,       // Event wait list\n",
        "        nullptr        // Event object\n",
        "    );\n",
        "\n",
        "    // Wait until kernel execution is complete\n",
        "    clFinish(queue);\n",
        "\n",
        "    // Record end time after kernel execution\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Read results from device buffer dC to host vector C\n",
        "    clEnqueueReadBuffer(\n",
        "        queue,         // Command queue\n",
        "        dC,            // Device buffer\n",
        "        CL_TRUE,       // Blocking read\n",
        "        0,             // Offset\n",
        "        size,          // Number of bytes to read\n",
        "        C.data(),      // Host destination\n",
        "        0,             // Number of events to wait for\n",
        "        nullptr,       // Event wait list\n",
        "        nullptr        // Event object\n",
        "    );\n",
        "\n",
        "    // Print kernel execution time in milliseconds\n",
        "    std::cout << \"Vector Add Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(end - start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    // Exit program successfully\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBdNul7rqBoC",
        "outputId": "f8e25927-7f07-44a5-d644-e9bd86bdc36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ vector_add.cpp -lOpenCL -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUAEh5YyqC9p",
        "outputId": "71383ebe-3427-4e63-9676-375a97584cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Add Time: 0.000639 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "// Write the following OpenCL kernel to a file named matrix_mul.cl\n",
        "%%writefile matrix_mul.cl\n",
        "\n",
        "// Define an OpenCL kernel function for matrix multiplication\n",
        "__kernel void matrix_mul(\n",
        "\n",
        "    // Pointer to matrix A stored in global memory (read-only)\n",
        "    __global const float* A,\n",
        "\n",
        "    // Pointer to matrix B stored in global memory (read-only)\n",
        "    __global const float* B,\n",
        "\n",
        "    // Pointer to matrix C stored in global memory (write-only result)\n",
        "    __global float* C,\n",
        "\n",
        "    // Number of rows in matrix A and matrix C\n",
        "    int N,\n",
        "\n",
        "    // Number of columns in matrix A and rows in matrix B\n",
        "    int M,\n",
        "\n",
        "    // Number of columns in matrix B and matrix C\n",
        "    int K\n",
        ") {\n",
        "\n",
        "    // Get the global row index for this work-item\n",
        "    int row = get_global_id(0);\n",
        "\n",
        "    // Get the global column index for this work-item\n",
        "    int col = get_global_id(1);\n",
        "\n",
        "    // Initialize accumulator for dot product\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Loop over the shared dimension M\n",
        "    for (int i = 0; i < M; i++)\n",
        "\n",
        "        // Multiply corresponding elements and accumulate the result\n",
        "        sum += A[row * M + i] * B[i * K + col];\n",
        "\n",
        "    // Store the computed value in the result matrix C\n",
        "    C[row * K + col] = sum;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4q-m4vqGHi",
        "outputId": "22eacb06-dc94-4211-a55b-db32980f69a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "// Write the following C++ OpenCL host program to a file named matrix_mul.cpp\n",
        "%%writefile matrix_mul.cpp\n",
        "\n",
        "// Specify the target OpenCL version (1.2)\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "\n",
        "// Include the main OpenCL header\n",
        "#include <CL/cl.h>\n",
        "\n",
        "// Include standard input/output stream library\n",
        "#include <iostream>\n",
        "\n",
        "// Include vector container from the C++ standard library\n",
        "#include <vector>\n",
        "\n",
        "// Include file stream library for reading kernel source\n",
        "#include <fstream>\n",
        "\n",
        "// Include chrono library for performance timing\n",
        "#include <chrono> // for timing\n",
        "\n",
        "// Function to load OpenCL kernel source code from a file\n",
        "std::string loadKernel(const char* filename) {\n",
        "\n",
        "    // Open the kernel file\n",
        "    std::ifstream file(filename);\n",
        "\n",
        "    // Read entire file into a string and return it\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),\n",
        "        std::istreambuf_iterator<char>()\n",
        "    );\n",
        "}\n",
        "\n",
        "// Main program entry point\n",
        "int main() {\n",
        "\n",
        "    // Define matrix dimensions: A (N×M), B (M×K), C (N×K)\n",
        "    const int N = 256, M = 256, K = 256;\n",
        "\n",
        "    // Allocate and initialize matrix A with all elements equal to 1.0\n",
        "    std::vector<float> A(N * M, 1.0f);\n",
        "\n",
        "    // Allocate and initialize matrix B with all elements equal to 2.0\n",
        "    std::vector<float> B(M * K, 2.0f);\n",
        "\n",
        "    // Allocate matrix C to store the result\n",
        "    std::vector<float> C(N * K);\n",
        "\n",
        "    // Declare OpenCL platform identifier\n",
        "    cl_platform_id platform;\n",
        "\n",
        "    // Declare OpenCL device identifier\n",
        "    cl_device_id device;\n",
        "\n",
        "    // Get the first available OpenCL platform\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "\n",
        "    // Get the first available OpenCL device (CPU or GPU)\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 1, &device, nullptr);\n",
        "\n",
        "    // Create an OpenCL context for the selected device\n",
        "    cl_context context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    // Create a command queue for issuing commands to the device\n",
        "    cl_command_queue queue = clCreateCommandQueue(context, device, 0, nullptr);\n",
        "\n",
        "    // Create OpenCL buffer for matrix A and copy data from host to device\n",
        "    cl_mem dA = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        A.size() * sizeof(float),\n",
        "        A.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Create OpenCL buffer for matrix B and copy data from host to device\n",
        "    cl_mem dB = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n",
        "        B.size() * sizeof(float),\n",
        "        B.data(),\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Create OpenCL buffer for matrix C (output only)\n",
        "    cl_mem dC = clCreateBuffer(\n",
        "        context,\n",
        "        CL_MEM_WRITE_ONLY,\n",
        "        C.size() * sizeof(float),\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Load kernel source code from file\n",
        "    std::string srcCode = loadKernel(\"matrix_mul.cl\");\n",
        "\n",
        "    // Convert kernel source code to C-style string\n",
        "    const char* src = srcCode.c_str();\n",
        "\n",
        "    // Create OpenCL program object from source code\n",
        "    cl_program program = clCreateProgramWithSource(context, 1, &src, nullptr, nullptr);\n",
        "\n",
        "    // Compile the OpenCL program for the selected device\n",
        "    clBuildProgram(program, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    // Create kernel object from the compiled program\n",
        "    cl_kernel kernel = clCreateKernel(program, \"matrix_mul\", nullptr);\n",
        "\n",
        "    // Set kernel argument 0: pointer to matrix A\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "\n",
        "    // Set kernel argument 1: pointer to matrix B\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "\n",
        "    // Set kernel argument 2: pointer to matrix C\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "\n",
        "    // Set kernel argument 3: number of rows N\n",
        "    clSetKernelArg(kernel, 3, sizeof(int), &N);\n",
        "\n",
        "    // Set kernel argument 4: shared dimension M\n",
        "    clSetKernelArg(kernel, 4, sizeof(int), &M);\n",
        "\n",
        "    // Set kernel argument 5: number of columns K\n",
        "    clSetKernelArg(kernel, 5, sizeof(int), &K);\n",
        "\n",
        "    // Define global work size (2D): one work-item per element of matrix C\n",
        "    size_t globalSize[2] = { (size_t)N, (size_t)K };\n",
        "\n",
        "    // ======== start timing ========\n",
        "\n",
        "    // Record start time before kernel execution\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Enqueue the matrix multiplication kernel for execution\n",
        "    clEnqueueNDRangeKernel(\n",
        "        queue,\n",
        "        kernel,\n",
        "        2,\n",
        "        nullptr,\n",
        "        globalSize,\n",
        "        nullptr,\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Wait until kernel execution is finished\n",
        "    clFinish(queue);\n",
        "\n",
        "    // Record end time after kernel execution\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Compute elapsed time in milliseconds\n",
        "    std::chrono::duration<double, std::milli> duration_ms = end - start;\n",
        "\n",
        "    // Print kernel execution time\n",
        "    std::cout << \"Matrix multiplication execution time: \"\n",
        "              << duration_ms.count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    // Read the result matrix C from device to host memory\n",
        "    clEnqueueReadBuffer(\n",
        "        queue,\n",
        "        dC,\n",
        "        CL_TRUE,\n",
        "        0,\n",
        "        C.size() * sizeof(float),\n",
        "        C.data(),\n",
        "        0,\n",
        "        nullptr,\n",
        "        nullptr\n",
        "    );\n",
        "\n",
        "    // Print completion message\n",
        "    std::cout << \"Matrix multiplication finished\\n\";\n",
        "\n",
        "    // Exit program successfully\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BayvBrdaqH9g",
        "outputId": "ff44f04f-17d0-4ecd-cb70-54e14b6dccd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ matrix_mul.cpp -lOpenCL -o matrix_mul\n",
        "!./matrix_mul\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgXT2BosqJht",
        "outputId": "23c9f1f1-bb30-49ac-bc5a-70739d60daee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication execution time: 0.00042 ms\n",
            "Matrix multiplication finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Control Questions – OpenCL\n",
        "\n",
        "### 1. What are the main types of memory used in OpenCL?\n",
        "\n",
        "OpenCL uses several types of memory:\n",
        "\n",
        "- **Global memory**  \n",
        "  - Accessible by all work-items on the device.  \n",
        "  - Large capacity but slow.  \n",
        "  - Used to store large arrays of data.\n",
        "\n",
        "- **Local memory**  \n",
        "  - Shared memory for all work-items within a work-group.  \n",
        "  - Fast, but limited in size.  \n",
        "  - Ideal for communication between threads in a group.\n",
        "\n",
        "- **Private memory**  \n",
        "  - Memory private to each work-item.  \n",
        "  - Typically implemented in registers.  \n",
        "  - Very fast but very limited in size.\n",
        "\n",
        "- **Constant memory**  \n",
        "  - Read-only memory accessible by all work-items.  \n",
        "  - Optimized for simultaneous reads by many threads.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. How to configure global and local work sizes?\n",
        "\n",
        "- **Global work size**  \n",
        "  - Total number of work-items that will execute the kernel.  \n",
        "  - Usually matches the total size of the dataset.\n",
        "\n",
        "- **Local work size**  \n",
        "  - Number of work-items in a single work-group.  \n",
        "  - Local memory and synchronization are used within a work-group.  \n",
        "  - Proper tuning affects performance:  \n",
        "    - Too small → low GPU utilization  \n",
        "    - Too large → may exceed local memory capacity\n",
        "\n",
        "**Example:**\n",
        "```c\n",
        "size_t globalSize[2] = {N, K};\n",
        "size_t localSize[2] = {16, 16}; // 16x16 threads per work-group\n",
        "clEnqueueNDRangeKernel(queue, kernel, 2, nullptr, globalSize, localSize, 0, nullptr, nullptr);\n",
        "```\n",
        "\n",
        "3. How does OpenCL differ from CUDA?\n",
        "\n",
        "OpenCL\n",
        "\n",
        "Cross-platform standard for CPU, GPU, FPGA.\n",
        "\n",
        "Works on devices from different vendors.\n",
        "\n",
        "More portable but more complex to configure and optimize.\n",
        "\n",
        "CUDA\n",
        "\n",
        "Proprietary API from NVIDIA.\n",
        "\n",
        "Works only on NVIDIA GPUs.\n",
        "\n",
        "Offers simpler and highly optimized control over memory and threads on NVIDIA hardware.\n",
        "\n",
        "4. What are the advantages of using OpenCL?\n",
        "\n",
        "Code portability across different devices (CPU, GPU, FPGA).\n",
        "\n",
        "Ability to utilize parallelism and accelerate computation on various architectures.\n",
        "\n",
        "Fine-grained control over memory and threads for performance optimization.\n",
        "\n",
        "Supports modern multithreaded computations and scientific workloads.\n",
        "\n",
        "\n",
        "This is **ready to paste directly into your report**.  \n",
        "\n",
        "If you want, I can also **add a small diagram showing memory types and work-group hierarchy** to make your lab report look more professional. Do you want me to do that?"
      ],
      "metadata": {
        "id": "GmHrwsozrsr8"
      }
    }
  ]
}