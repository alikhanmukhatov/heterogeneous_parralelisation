{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv20ikjap9sW",
        "outputId": "c8b4093a-782a-4196-80ab-52865ccc8428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cl\n"
          ]
        }
      ],
      "source": [
        "%%writefile kernel.cl\n",
        "__kernel void vector_add(\n",
        "    __global const float* A,\n",
        "    __global const float* B,\n",
        "    __global float* C\n",
        ") {\n",
        "    int id = get_global_id(0);\n",
        "    C[id] = A[id] + B[id];\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cpp\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "#include <CL/cl.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "\n",
        "std::string loadKernel(const char* filename) {\n",
        "    std::ifstream file(filename);\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),\n",
        "        std::istreambuf_iterator<char>()\n",
        "    );\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1 << 20;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    std::vector<float> A(N, 1.0f);\n",
        "    std::vector<float> B(N, 2.0f);\n",
        "    std::vector<float> C(N);\n",
        "\n",
        "    cl_platform_id platform;\n",
        "    cl_device_id device;\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 1, &device, nullptr);\n",
        "\n",
        "    cl_context context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, nullptr);\n",
        "    cl_command_queue queue = clCreateCommandQueue(context, device, 0, nullptr);\n",
        "\n",
        "    cl_mem dA = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, size, A.data(), nullptr);\n",
        "    cl_mem dB = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, size, B.data(), nullptr);\n",
        "    cl_mem dC = clCreateBuffer(context, CL_MEM_WRITE_ONLY, size, nullptr, nullptr);\n",
        "\n",
        "    std::string srcCode = loadKernel(\"kernel.cl\");\n",
        "    const char* src = srcCode.c_str();\n",
        "    cl_program program = clCreateProgramWithSource(context, 1, &src, nullptr, nullptr);\n",
        "    clBuildProgram(program, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    cl_kernel kernel = clCreateKernel(program, \"vector_add\", nullptr);\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "\n",
        "    size_t globalSize = N;\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    clEnqueueNDRangeKernel(queue, kernel, 1, nullptr, &globalSize, nullptr, 0, nullptr, nullptr);\n",
        "    clFinish(queue);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    clEnqueueReadBuffer(queue, dC, CL_TRUE, 0, size, C.data(), 0, nullptr, nullptr);\n",
        "\n",
        "    std::cout << \"Vector Add Time: \"\n",
        "              << std::chrono::duration<double, std::milli>(end - start).count()\n",
        "              << \" ms\\n\";\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBdNul7rqBoC",
        "outputId": "f8e25927-7f07-44a5-d644-e9bd86bdc36b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ vector_add.cpp -lOpenCL -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUAEh5YyqC9p",
        "outputId": "71383ebe-3427-4e63-9676-375a97584cc8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Add Time: 0.000639 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cl\n",
        "__kernel void matrix_mul(\n",
        "    __global const float* A,\n",
        "    __global const float* B,\n",
        "    __global float* C,\n",
        "    int N, int M, int K\n",
        ") {\n",
        "    int row = get_global_id(0);\n",
        "    int col = get_global_id(1);\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    for (int i = 0; i < M; i++)\n",
        "        sum += A[row * M + i] * B[i * K + col];\n",
        "\n",
        "    C[row * K + col] = sum;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4q-m4vqGHi",
        "outputId": "22eacb06-dc94-4211-a55b-db32980f69a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cpp\n",
        "#define CL_TARGET_OPENCL_VERSION 120\n",
        "#include <CL/cl.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <chrono> // for timing\n",
        "\n",
        "std::string loadKernel(const char* filename) {\n",
        "    std::ifstream file(filename);\n",
        "    return std::string(\n",
        "        std::istreambuf_iterator<char>(file),\n",
        "        std::istreambuf_iterator<char>()\n",
        "    );\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 256, M = 256, K = 256;\n",
        "\n",
        "    std::vector<float> A(N * M, 1.0f);\n",
        "    std::vector<float> B(M * K, 2.0f);\n",
        "    std::vector<float> C(N * K);\n",
        "\n",
        "    cl_platform_id platform;\n",
        "    cl_device_id device;\n",
        "    clGetPlatformIDs(1, &platform, nullptr);\n",
        "    clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 1, &device, nullptr);\n",
        "\n",
        "    cl_context context = clCreateContext(nullptr, 1, &device, nullptr, nullptr, nullptr);\n",
        "    cl_command_queue queue = clCreateCommandQueue(context, device, 0, nullptr);\n",
        "\n",
        "    cl_mem dA = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, A.size() * sizeof(float), A.data(), nullptr);\n",
        "    cl_mem dB = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, B.size() * sizeof(float), B.data(), nullptr);\n",
        "    cl_mem dC = clCreateBuffer(context, CL_MEM_WRITE_ONLY, C.size() * sizeof(float), nullptr, nullptr);\n",
        "\n",
        "    std::string srcCode = loadKernel(\"matrix_mul.cl\");\n",
        "    const char* src = srcCode.c_str();\n",
        "    cl_program program = clCreateProgramWithSource(context, 1, &src, nullptr, nullptr);\n",
        "    clBuildProgram(program, 1, &device, nullptr, nullptr, nullptr);\n",
        "\n",
        "    cl_kernel kernel = clCreateKernel(program, \"matrix_mul\", nullptr);\n",
        "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &dA);\n",
        "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &dB);\n",
        "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &dC);\n",
        "    clSetKernelArg(kernel, 3, sizeof(int), &N);\n",
        "    clSetKernelArg(kernel, 4, sizeof(int), &M);\n",
        "    clSetKernelArg(kernel, 5, sizeof(int), &K);\n",
        "\n",
        "    size_t globalSize[2] = { (size_t)N, (size_t)K };\n",
        "\n",
        "    // ======== start timing ========\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    clEnqueueNDRangeKernel(queue, kernel, 2, nullptr, globalSize, nullptr, 0, nullptr, nullptr);\n",
        "    clFinish(queue);\n",
        "\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double, std::milli> duration_ms = end - start;\n",
        "    std::cout << \"Matrix multiplication execution time: \" << duration_ms.count() << \" ms\\n\";\n",
        "\n",
        "    clEnqueueReadBuffer(queue, dC, CL_TRUE, 0, C.size() * sizeof(float), C.data(), 0, nullptr, nullptr);\n",
        "\n",
        "    std::cout << \"Matrix multiplication finished\\n\";\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BayvBrdaqH9g",
        "outputId": "ff44f04f-17d0-4ecd-cb70-54e14b6dccd9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ matrix_mul.cpp -lOpenCL -o matrix_mul\n",
        "!./matrix_mul\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgXT2BosqJht",
        "outputId": "23c9f1f1-bb30-49ac-bc5a-70739d60daee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication execution time: 0.00042 ms\n",
            "Matrix multiplication finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Control Questions – OpenCL\n",
        "\n",
        "### 1. What are the main types of memory used in OpenCL?\n",
        "\n",
        "OpenCL uses several types of memory:\n",
        "\n",
        "- **Global memory**  \n",
        "  - Accessible by all work-items on the device.  \n",
        "  - Large capacity but slow.  \n",
        "  - Used to store large arrays of data.\n",
        "\n",
        "- **Local memory**  \n",
        "  - Shared memory for all work-items within a work-group.  \n",
        "  - Fast, but limited in size.  \n",
        "  - Ideal for communication between threads in a group.\n",
        "\n",
        "- **Private memory**  \n",
        "  - Memory private to each work-item.  \n",
        "  - Typically implemented in registers.  \n",
        "  - Very fast but very limited in size.\n",
        "\n",
        "- **Constant memory**  \n",
        "  - Read-only memory accessible by all work-items.  \n",
        "  - Optimized for simultaneous reads by many threads.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. How to configure global and local work sizes?\n",
        "\n",
        "- **Global work size**  \n",
        "  - Total number of work-items that will execute the kernel.  \n",
        "  - Usually matches the total size of the dataset.\n",
        "\n",
        "- **Local work size**  \n",
        "  - Number of work-items in a single work-group.  \n",
        "  - Local memory and synchronization are used within a work-group.  \n",
        "  - Proper tuning affects performance:  \n",
        "    - Too small → low GPU utilization  \n",
        "    - Too large → may exceed local memory capacity\n",
        "\n",
        "**Example:**\n",
        "```c\n",
        "size_t globalSize[2] = {N, K};\n",
        "size_t localSize[2] = {16, 16}; // 16x16 threads per work-group\n",
        "clEnqueueNDRangeKernel(queue, kernel, 2, nullptr, globalSize, localSize, 0, nullptr, nullptr);\n",
        "```\n",
        "\n",
        "3. How does OpenCL differ from CUDA?\n",
        "\n",
        "OpenCL\n",
        "\n",
        "Cross-platform standard for CPU, GPU, FPGA.\n",
        "\n",
        "Works on devices from different vendors.\n",
        "\n",
        "More portable but more complex to configure and optimize.\n",
        "\n",
        "CUDA\n",
        "\n",
        "Proprietary API from NVIDIA.\n",
        "\n",
        "Works only on NVIDIA GPUs.\n",
        "\n",
        "Offers simpler and highly optimized control over memory and threads on NVIDIA hardware.\n",
        "\n",
        "4. What are the advantages of using OpenCL?\n",
        "\n",
        "Code portability across different devices (CPU, GPU, FPGA).\n",
        "\n",
        "Ability to utilize parallelism and accelerate computation on various architectures.\n",
        "\n",
        "Fine-grained control over memory and threads for performance optimization.\n",
        "\n",
        "Supports modern multithreaded computations and scientific workloads.\n",
        "\n",
        "\n",
        "This is **ready to paste directly into your report**.  \n",
        "\n",
        "If you want, I can also **add a small diagram showing memory types and work-group hierarchy** to make your lab report look more professional. Do you want me to do that?"
      ],
      "metadata": {
        "id": "GmHrwsozrsr8"
      }
    }
  ]
}